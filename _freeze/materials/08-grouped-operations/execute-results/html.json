{
  "hash": "ebfd0457f535f04a9a047265589269bf",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Grouped operations\n---\n\n::: {.callout-tip}\n#### Learning objectives\n\n- \n:::\n\n\n## Context\n\nWe’ve done different types of operations, all on the entire data set. Sometimes there is structure within the data, such as different groups (e.g. genotypes, patient cohorts, geographical areas etc). We might then want information on a group-by-group basis.\n\n## Section setup {#setup_grouped_operations}\n\n::: {.callout-note collapse=\"true\"}\n## Click to expand\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nWe'll continue this section with the script named `05-manipulation.R`. If needed, add the following code to the top of your script and run it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# A collection of R packages designed for data science\nlibrary(tidyverse)\n\nsurveys <- read_csv(\"data/surveys.csv\")\n```\n:::\n\n\n## Python\n\nWe'll continue this section with the script named `05-manipulation.py`. If needed, add the following code to the top of your script and run it.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# A Python data analysis and manipulation tool\nimport pandas as pd\n\n# Python equivalent of `ggplot2`\nfrom plotnine import *\n\nsurveys = pd.read_csv(\"data/surveys.csv\")\n```\n:::\n\n\n:::\n:::\n\n## Split-apply-combine\n\nConceptually, this kind of operation can be referred to as split-apply-combine, because we split the data, apply some function and then combine the outcome.\n\nLet's illustrate this with an example. @fig-groupby_table shows a hypothetical data set, where we have temperature and rainfall measurements for different cities.\n\n![An example of a table with groups](images/groupby_table.png){#fig-groupby_table}\n\nLet's assume we were interested in the average temperature for each city. We would have to do the following:\n\n1. Split the data by `city`\n2. Calculate the average `temperature`\n3. Combine the outcome together in a new table\n\nThis is visualised in @fig-groupby_split.\n\n![Split-apply-combine](images/groupby_split.png){#fig-groupby_split}\n\n## Summary operations\n\nLet's put this into practice with our data set.\n\n### Summarising data\n\nA common task in data analysis is to summarise variables to get the mean and the variation around it.\n\nFor example, let’s calculate what the mean and standard deviation are for `weight`.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nWe can achieve this task using the `summarise()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurveys |> \n  summarise(weight_mean = mean(weight, na.rm  = TRUE),\n            weight_sd = sd(weight, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  weight_mean weight_sd\n        <dbl>     <dbl>\n1        42.7      36.6\n```\n\n\n:::\n:::\n\n\nA couple of things to notice:\n\nThe output of `summarise` is a new table, where each column is named according to the input to `summarise()`.\n\nWithin `summarise()` we should use functions for which the output is a single value.\nAlso notice that, above, we used the `na.rm` option within the summary functions, so that they ignored missing values when calculating the respective statistics.\n\n## Python\n\n:::\n\n::: {.callout-tip}\n## Summary functions\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nThere are many functions whose input is a vector (or a column in a table) and the output is a single number. Here are several common ones:\n\n* `mean(x)` - arithmetic mean\n* `median(x)` - median\n* `sd(x)` - standard deviation\n* `var(x)` - variance\n* `IQR(x)` - interquartile range\n* `mad(x)` - median absolute deviation\n* `min(x)` and `max(x)` - minimum and maximum\n* `quantile(x, probs = 0.75)` - [quantile](https://simple.wikipedia.org/wiki/Quantile) (use the `probs` option to set the quantile of your choosing)\n* `sum(x)` - addition of all values in `x`\n* `n_distinct(x)` (from `dplyr`) - the number of distinct values in the vector `x`\n\nAll of these have the option `na.rm`, which tells the function remove missing values before doing the calculation.\n\n## Python\n\n:::\n:::\n\n### Grouped summaries\n\nIn most cases we want to calculate summary statistics across groups of our data. \n\n::: {.panel-tabset group=\"language\"}\n## R\n\nWe can achieve this by combining `summarise()` with the `group_by()` function. For example, let’s modify the previous example to calculate the summary for each `sex` group:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurveys |> \n  group_by(sex) |> \n  summarise(weight_mean = mean(weight, na.rm  = TRUE),\n            weight_sd = sd(weight, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  sex   weight_mean weight_sd\n  <chr>       <dbl>     <dbl>\n1 F            42.2      36.8\n2 M            43.0      36.2\n3 <NA>         64.7      62.2\n```\n\n\n:::\n:::\n\n\nThe table output now includes both the columns we defined within `summarise()` as well as the grouping columns defined within `group_by()`.\n\n## Python\n:::\n\n## Counting data\n\nCounting or tallying data is an extremely useful way of getting to know your data better.\n\n### Simple counting\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nWe can use the `count()` function from `dplyr` to count data. It always returns the number of rows it counts.\n\nFor example, this gives us the total number of observations (rows) in our data set:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncount(surveys)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n      n\n  <int>\n1 35549\n```\n\n\n:::\n:::\n\n\nWe can also do that using conditional statements:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# count the observations from the year 1982\nsurveys |> \n  filter(year == 1982) |> \n  count()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n      n\n  <int>\n1  1978\n```\n\n\n:::\n:::\n\n\n\n## Python\n\n:::\n\n### Counting by group\n\nCounting really comes into its own when we're combining this with some grouping. For example, we might be interested in the number of observations for each year.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurveys |> \n  count(year)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 26 × 2\n    year     n\n   <dbl> <int>\n 1  1977   503\n 2  1978  1048\n 3  1979   719\n 4  1980  1415\n 5  1981  1472\n 6  1982  1978\n 7  1983  1673\n 8  1984   981\n 9  1985  1438\n10  1986   942\n# ℹ 16 more rows\n```\n\n\n:::\n:::\n\n\nWe can also easily visualise this (we can pipe straight into `ggplot()`). We use `geom_col()` to create a bar chart of the number of observations per year. We count by `sex` and use this variable to fill the colour of the bars.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurveys |> \n  count(sex, year) |> \n  ggplot(aes(x = year, y = n, fill = sex)) +\n  geom_col()\n```\n\n::: {.cell-output-display}\n![](08-grouped-operations_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n::: {.callout-important}\n## Counting within a summary pipeline\n\nOften we want to do counting when we're creating summaries. The `count()` function can't be used within `summarise()`, but there is a special helper function called `n()`. Look at the following example, where we group by year, filter the data, create some summary statistic and also count the number of rows within each group.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurveys |> \n  group_by(year) |>                                   # group the data\n  filter(year %in% c(1981, 1982)) |>                  # filter a subset of years\n  summarise(mean_weight = mean(weight, na.rm = TRUE), # calculate mean weight\n            n_obs = n()) |>                           # number of rows\n  ungroup()                                           # drop the grouping\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 3\n   year mean_weight n_obs\n  <dbl>       <dbl> <int>\n1  1981        65.8  1472\n2  1982        53.8  1978\n```\n\n\n:::\n:::\n\n\n:::\n\n## Python\n\n:::\n\n### Counting missing data\n\nOh, missing data! How we've missed you. For something that isn't there, is has quite the presence. But, it is an important consideration in data analysis. We've [already seen](#missingdata-revisited) how we can remove missing data from and also explored ways to visualise them.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nWe have seen how to use the `summary()` function to find missing values. Here we'll see (even more) ways to tally them.\n\nWe can use the `is.na()` function to great effect, within a `summarise()` pipeline. We can negate with `!is.na()` to find non-missing values. Again, using the `sum()` function then enables us to tally how many missing / non-missing values there are.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurveys |> \n  summarise(obs_present = sum(!is.na(species_id)),    # count non-missing data\n            obs_absent = sum(is.na(species_id)),      # count missing data\n            n_obs = n(),                              # total number of rows\n            precentage_absent = \n              (obs_absent / n_obs) * 100) |>          # percentage of missing data\n  ungroup()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 4\n  obs_present obs_absent n_obs precentage_absent\n        <int>      <int> <int>             <dbl>\n1       34786        763 35549              2.15\n```\n\n\n:::\n:::\n\n\n## Python\n\n:::\n\n## Grouped operations\n\n### Grouped filters\nLO: grouped filters\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n## Python\n\n:::\n\n### Grouped changes\nLO: grouped mutate\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n## Python\n\n:::\n\n### To ungroup or not ungroup\nLO: the importance of ungrouping\n\n\n\n## Summary\n\n::: {.callout-tip}\n#### Key points\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n-\n\n## Python\n\n-\n:::\n\n:::\n",
    "supporting": [
      "08-grouped-operations_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}