{
  "hash": "82b22bdd72367d64ffe6e123d90ff4d7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Reshaping data\n---\n\n::: {.callout-tip}\n#### Learning objectives\n\n- Learn what long and wide data formats are.\n- Be able to recognise when best to use each.\n- Be able to switch from long to wide and back.\n:::\n\n## Context\nSo far, we have provided data in the most convenient format. In real life, this is of course not always the case, because people collect data in a format that works best for them - not the computer. So, sometimes we need to change the shape of our data, so we can calculate or visualise the data we'd like.\n\n## Section setup {#setup_reshaping_data}\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nWe'll continue this section with the script named `da4-09-reshaping-data.R`. If needed, add the following code to the top of your script and run it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# A collection of R packages designed for data science\nlibrary(tidyverse)\n\nsurveys_join <- read_csv(\"data/surveys_join.csv\")\n```\n:::\n\n\n## Python\n\nWe'll continue this section with the Notebook named `da4-09-reshaping-data.ipynb`. Add the following code to the first cell and run it.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# A Python data analysis and manipulation tool\nimport pandas as pd\n\n# Python equivalent of `ggplot2`\nfrom plotnine import *\n\n# If using seaborn for plotting\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsurveys_join = pd.read_csv(\"data/surveys_join.csv\")\n```\n:::\n\n\n:::\n\n## Data reshaping\n\nLet's look at a hypothetical data set, based on the type of variables we've come across in the `surveys` data.\n\n![Wide and long data formats contain the same information](images/long_and_wide.png){#fig-long_wide}\n\nThe data that is present in both tables is the same - it's just encoded slightly differently.\n\n1. The \"long\" format is where we have a column for each of the types of things we measured or recorded in our data. In other words, each variable has its own column.\n2. The \"wide\" format occurs when we have data relating to the same measured thing in different columns. In this case, we have values related to our *metric* spread across multiple columns (a column each for a year).\n\n::: {.callout-note}\n## Wide or long?\n\nNeither of these formats is necessarily more correct than the other: it will depend on what analysis you intend on doing. However, it is worth mentioning that the \"long\" format is often preferred, as it is clearer how many distinct types of variables we have in the data.\n\nTo figure out which format you might need, it may help to think of which visualisations you may want to build with `ggplot()` (or other packages, for that example). Taking the above example:\n\n* If you were interested in looking at the change of `weight` across years for each individual, then the long format is more suitable to define each aesthetic of such a graph: `aes(x = year, y = weight, colour = record_id)`.\n* If you were interested in the correlation of this metric between 2021 and 2022, then the wide format would be more suitable: `aes(x = yr_2021, y = yr_2022, colour = record_id)`.\n:::\n\n## From long to wide\n\nLet's illustrate that with a dummy data set, called `surveys_join`. In this synthetic data set we have `weight` measurements for individuals across four years: 2021 - 2024. This means that there are four measurements for each `record_id`.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read in the data\nsurveys_join <- read_csv(\"data/surveys_join.csv\")\n\n# Look at the first few rows\nhead(surveys_join)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  record_id  year weight\n      <dbl> <dbl>  <dbl>\n1       166  2021   195.\n2       166  2022   190.\n3       166  2023   184.\n4       166  2024   182 \n5       228  2021   192.\n6       228  2022   189 \n```\n\n\n:::\n:::\n\n\nWe can reshape our data from long to wide as follows, where I do *not* overwrite the existing data, but instead just pipe it through to the `head()` function, so we can see what the `pivot_wider()` function is doing:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurveys_join |> \n  pivot_wider(names_from = \"year\",\n              values_from = \"weight\",\n              names_prefix = \"yr_\") |>\n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n  record_id yr_2021 yr_2022 yr_2023 yr_2024\n      <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1       166    195.    190.    184.    182 \n2       228    192.    189     188     179 \n3       337    181.    176.    177     168.\n4       330    172.    170.    165.    157.\n5       205    177.    176.    167.    166.\n6       878    170.    172     167.    161.\n```\n\n\n:::\n:::\n\n\nLet's unpack that a bit. \n\nThe `pivot_wider()` function needs at least the first two arguments:\n\n1. `names_from =` the column who's values we want to use for our new column names (`year`)\n2. `values_from =` the column who's values we want to use to populate these new columns (`weight`)\n3. `names_prefix =` a prefix for our column names (optional)\n\nHere we also add `names_prefix = \"yr_\"`, otherwise the column names would contain only numbers and that's not very good programming habit.\n\nLet's assign it to a new object and then visualise some of the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurveys_wide <- surveys_join |> \n  pivot_wider(names_from = \"year\",\n              values_from = \"weight\",\n              names_prefix = \"yr_\")\n```\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Read in the data\nsurveys_join = pd.read_csv(\"data/surveys_join.csv\")\n\n# Look at the first few rows\nsurveys_join.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   record_id  year  weight\n0        166  2021   195.4\n1        166  2022   189.5\n2        166  2023   183.6\n3        166  2024   182.0\n4        228  2021   191.9\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nsurveys_wide = surveys_join.pivot(\n    index = \"record_id\",\n    columns = \"year\",\n    values = \"weight\"\n)\n\n# Add 'yr_' prefix to year columns\nsurveys_wide.columns = [f\"yr_{col}\" for col in surveys_wide.columns]\n\n# Reset index to make 'record_id' a column again\nsurveys_wide = surveys_wide.reset_index()\n\nsurveys_wide.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   record_id  yr_2021  yr_2022  yr_2023  yr_2024\n0        118    199.5    192.8    192.6    187.6\n1        160    192.5    189.0    184.3    181.4\n2        166    195.4    189.5    183.6    182.0\n3        178    190.1    188.4    182.2    177.5\n4        184    195.1    186.7    193.5    187.3\n```\n\n\n:::\n:::\n\n\n:::\n\nWe can then use this to visualise possible relationships between the different years:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(surveys_wide, aes(x = yr_2021, y = yr_2022)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![Scatterplot of `weight` for 2021 and 2022](da4-09-reshaping-data_files/figure-html/fig-weight_2122-1.png){#fig-weight_2122 width=672}\n:::\n:::\n\n\nIf you'd be interested in comparisons across all years, you'd have to use the original, long format because there isn't a single column in the wide table that contains all of the year information.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(surveys_join, aes(x = factor(year), y =  weight)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![Boxplot of `weight` for 2021 - 2024](da4-09-reshaping-data_files/figure-html/fig-weight_by_year-1.png){#fig-weight_by_year width=672}\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\np = (ggplot(surveys_wide, aes(x = \"yr_2021\", y = \"yr_2022\")) +\n    geom_point())\n    \np.show()\n```\n\n::: {.cell-output-display}\n![Scatterplot of `weight` for 2021 and 2022](da4-09-reshaping-data_files/figure-html/fig-weight_2122_py-1.png){#fig-weight_2122_py width=614}\n:::\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## Seaborn equivalent\n\n\n::: {.cell}\n\n```{.python .cell-code}\nsns.scatterplot(\n    data = surveys_wide,\n    x = \"yr_2021\",\n    y = \"yr_2022\"\n)\n\nplt.title(\"Scatterplot of yr_2021 vs yr_2022\")\nplt.show()\n```\n\n::: {.cell-output-display}\n![Scatterplot of `weight` for 2021 and 2022](da4-09-reshaping-data_files/figure-html/fig-weight_2122_seaborn-3.png){#fig-weight_2122_seaborn width=672}\n:::\n:::\n\n:::\n\n\n::: {.cell}\n\n```{.python .cell-code}\np = (ggplot(surveys_join, aes(x = \"factor(year)\", y = \"weight\")) +\n    geom_boxplot())\n\np.show()\n```\n\n::: {.cell-output-display}\n![Boxplot of `weight` for 2021 - 2024](da4-09-reshaping-data_files/figure-html/fig-weight_by_year_py-5.png){#fig-weight_by_year_py width=614}\n:::\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## Seaborn equivalent\n\n\n::: {.cell}\n\n```{.python .cell-code}\nsns.boxplot(\n    data = surveys_join,\n    x = \"year\", # seaborn treats numeric as categorical automatically if discrete\n    y = \"weight\"\n)\n\nplt.title(\"Weight by year (boxplot)\")\nplt.show()\n```\n\n::: {.cell-output-display}\n![Boxplot of `weight` for 2021 - 2024](da4-09-reshaping-data_files/figure-html/fig-weight_by_year_seaborn-7.png){#fig-weight_by_year_seaborn width=672}\n:::\n:::\n\n:::\n\n:::\n\n## From wide to long\nWe can reshape our data from wide to long. This is more or less the inverse of what we did above.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurveys_wide |> \n  pivot_longer(cols = -record_id,\n               names_to = \"year\",\n               values_to = \"weight\",\n               names_prefix = \"yr_\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 200 × 3\n   record_id year  weight\n       <dbl> <chr>  <dbl>\n 1       166 2021    195.\n 2       166 2022    190.\n 3       166 2023    184.\n 4       166 2024    182 \n 5       228 2021    192.\n 6       228 2022    189 \n 7       228 2023    188 \n 8       228 2024    179 \n 9       337 2021    181.\n10       337 2022    176.\n# ℹ 190 more rows\n```\n\n\n:::\n:::\n\n\nHere we use the following arguments:\n\n1. `cols =` this tells `pivot_longer()` which columns to pivot - here we want to use all but the `record_id` column\n2. `names_to =` the name of the column that gets to hold the column names (e.g. `yr_2021`, `yr_2022` ...)\n3. `values_to =` the name of the column that will contain the measured values (here those are the `weight` measurements)\n4. `names_prefix =` here we tell it that all column names have a prefix `yr_`, which then gets removed prior to populating the column\n\n## Python\n\nTo go back to the long format, we use the `.melt()` function.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nsurveys_long = surveys_wide.melt(\n    id_vars = \"record_id\",            # columns to keep fixed\n    var_name = \"year\",                # name of the new 'year' column\n    value_name = \"weight\"             # name of the new 'weight' column\n)\n\nsurveys_long.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   record_id     year  weight\n0        118  yr_2021   199.5\n1        160  yr_2021   192.5\n2        166  yr_2021   195.4\n3        178  yr_2021   190.1\n4        184  yr_2021   195.1\n```\n\n\n:::\n:::\n\n\nThis uses the following arguments:\n\n1. `id_vars =` this tells it what the `id` column is - `record_id` in our case, which does not get pivoted.\n2. `var_name =` the name of the column that gets to hold the column names (e.g. `yr_2021`, `yr_2022` ...)\n3. `value_name =` the name of the column that will contain the measured values (here those are the `weight` measurements)\n\nThis then creates a column `year` that contains the values `yr_2021`, `yr_2022`, `...`, since we added the prefix. If we want to remove the prefix we can do the following:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Remove 'yr_' prefix and convert year to integer\nsurveys_long[\"year\"] = surveys_long[\"year\"].str.replace(\"yr_\", \"\").astype(int)\n\nsurveys_long.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   record_id  year  weight\n0        118  2021   199.5\n1        160  2021   192.5\n2        166  2021   195.4\n3        178  2021   190.1\n4        184  2021   195.1\n```\n\n\n:::\n:::\n\n\n:::\n\n## Exercises\n\n### Reshaping: `auxin` {#sec-exr_reshape_auxin}\n\n::::: {.callout-exercise #ex-reshape_auxin}\n#### Reshaping data\n\n{{< level 2 >}}\n\nFor this exercise we'll be using the data from `data/auxin.csv`.\n\nThese are synthetic data that measure the plant height of *Arabidopsis thaliana*, in different genotypes (variants of the same species, here: `control` and `mutant`). It measures the effect the plant hormone auxin has on the growth of these plants.\n\nThis is done across different auxin concentrations (`none`, `low`, `high`).\n\nPlease do the following:\n\n1. Check the data structure.\n2. Create a \"wide\" table where, for each `replicate_id` / `genotype` pair, we have a column for each auxin concentration category. The data in these columns should be the `plant_height` measurements.\n3. Use this wide format to calculate the average plant height for each row.\n4. Change the data back to \"long\" format & check if you have your original data back.\n\n:::: {.callout-answer collapse=\"true\"}\nFirst, let's read in the data.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nauxin <- read_csv(\"data/auxin.csv\")\n```\n:::\n\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nauxin = pd.read_csv(\"data/auxin.csv\")\n```\n:::\n\n\n:::\n\n#### 1. Data structure\n\nBefore we make any changes, it's important to get a sense of how the data is currently shaped.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(auxin)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n  replicate_id genotype concentration plant_height\n         <dbl> <chr>    <chr>                <dbl>\n1            1 control  high                  31.7\n2            2 control  high                  33.6\n3            3 control  high                  31.3\n4            4 control  high                  30.5\n5            5 control  high                  30.4\n6            6 control  high                  30.1\n```\n\n\n:::\n:::\n\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nauxin.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   replicate_id genotype concentration  plant_height\n0             1  control          high          31.7\n1             2  control          high          33.6\n2             3  control          high          31.3\n3             4  control          high          30.5\n4             5  control          high          30.4\n```\n\n\n:::\n:::\n\n\n:::\n\nWe have 56 distinct `replicate_id` values, with at least 1 and up to 6 observations.\n\nThere are also three distinct concentration categories: high, low, none\n\n:::{.callout-important}\nCheck this yourself!\n:::\n\n#### 2. From long to wide\n\nSo what we want to do is get a table where for each `replicate_id` and `genotype` combination we have a separate column for each `concentration` category. That would allow us, for example, to calculate the average plant height for each measurement across the different concentration types.\n\nThe data should look something like:\n\n| replicate_id | genotype |  high |  low  |  none |\n|--------------|----------|-------|-------|-------|\n| 1            | control  |  31.7 |  38.5 |  42.7 |\n| 2            | control  |  33.6 |  35.9 |  46.8 |\n| 3            | control  |  31.3 |  38.4 |  42.8 |\n\nSo, let's do that.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nauxin_wide <- pivot_wider(auxin,\n            names_from = concentration,\n            values_from = plant_height)\n\nhead(auxin_wide)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n  replicate_id genotype  high   low  none\n         <dbl> <chr>    <dbl> <dbl> <dbl>\n1            1 control   31.7  38.5  42.7\n2            2 control   33.6  35.9  46.8\n3            3 control   31.3  38.4  42.8\n4            4 control   30.5  42.3  46.5\n5            5 control   30.4  32.8  46.5\n6            6 control   30.1  37.4  45.4\n```\n\n\n:::\n:::\n\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nauxin_wide = auxin.pivot(\n    index = [\"replicate_id\", \"genotype\"],\n    columns = \"concentration\",\n    values = \"plant_height\"\n).reset_index()\n\nauxin_wide.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nconcentration  replicate_id genotype  high   low  none\n0                         1  control  31.7  38.5  42.7\n1                         1   mutant  33.4  41.5  37.6\n2                         2  control  33.6  35.9  46.8\n3                         2   mutant  30.4  35.7  40.3\n4                         3  control  31.3  38.4  42.8\n```\n\n\n:::\n:::\n\n\n:::\n\n#### 3. Calculating average `plant_height`\n\nHaving the data in this format allows us to do:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nauxin_wide |> \n  mutate(avg_height = round((high + low + none) / 3, 1)) |> \n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n  replicate_id genotype  high   low  none avg_height\n         <dbl> <chr>    <dbl> <dbl> <dbl>      <dbl>\n1            1 control   31.7  38.5  42.7       37.6\n2            2 control   33.6  35.9  46.8       38.8\n3            3 control   31.3  38.4  42.8       37.5\n4            4 control   30.5  42.3  46.5       39.8\n5            5 control   30.4  32.8  46.5       36.6\n6            6 control   30.1  37.4  45.4       37.6\n```\n\n\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nauxin_wide.assign(\n    avg_height = auxin_wide[[\"high\", \"low\", \"none\"]] # select columns\n    .mean(axis = 1)                                  # calculate mean\n    .round(1)                                        # round to 1 decimal\n).head()                                             # display first few rows\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nconcentration  replicate_id genotype  high   low  none  avg_height\n0                         1  control  31.7  38.5  42.7        37.6\n1                         1   mutant  33.4  41.5  37.6        37.5\n2                         2  control  33.6  35.9  46.8        38.8\n3                         2   mutant  30.4  35.7  40.3        35.5\n4                         3  control  31.3  38.4  42.8        37.5\n```\n\n\n:::\n:::\n\n\n:::\n\n#### 4. From wide to long\n\nWe can also revert back to our original \"long\" format data. The data then has its original shape back, which follows:\n\n| replicate_id | genotype | concentration | plant_height |\n|--------------|----------|---------------|--------------|\n| 1            | control  | high          | 31.7         |\n| 2            | control  | high          | 33.6         |\n| 3            | control  | high          | 31.3         |\n\nSo, let's do that.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nauxin_long <- pivot_longer(auxin_wide,\n             cols = c(\"high\", \"low\", \"none\"),\n             names_to = \"concentration\",\n             values_to = \"plant_height\")\n```\n:::\n\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nauxin_long = auxin_wide.melt(\n    id_vars = [\"replicate_id\", \"genotype\"],  # columns to keep as identifiers\n    value_vars = [\"high\", \"low\", \"none\"],    # columns to unpivot\n    var_name = \"concentration\",              # new column for old column names\n    value_name = \"plant_height\"              # new column for values\n)\n```\n:::\n\n\n:::\n\nHowever, the eagle-eyed among you might have noticed that there are more rows in our data than we started with:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnrow(auxin)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 275\n```\n\n\n:::\n\n```{.r .cell-code}\nnrow(auxin_long)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 324\n```\n\n\n:::\n:::\n\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nauxin.shape[0]      # original data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n275\n```\n\n\n:::\n\n```{.python .cell-code}\nauxin_long.shape[0] # wide-and-back\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n324\n```\n\n\n:::\n:::\n\n\n:::\n\nThis is because in some of the `replicate_id` / `genotype` combinations there were no measured values for all three concentration types. This introduced missing values, which are then propagated when going back to a long format.\n\nSo, to deal with this, we can simply remove the values where the `plant_height` value is missing:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nauxin_long <- pivot_longer(auxin_wide,\n             cols = c(\"high\", \"low\", \"none\"),\n             names_to = \"concentration\",\n             values_to = \"plant_height\",\n             values_drop_na = TRUE)\n\nnrow(auxin_long)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 275\n```\n\n\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nauxin_long = (auxin_wide.melt(\n    id_vars = [\"replicate_id\", \"genotype\"],  # columns to keep as identifiers\n    value_vars = [\"high\", \"low\", \"none\"],    # columns to unpivot\n    var_name = \"concentration\",              # new column for old column names\n    value_name = \"plant_height\"              # new column for values\n)\n.dropna(subset = [\"plant_height\"])\n)\n\nauxin_long.shape[0]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n275\n```\n\n\n:::\n:::\n\n\n:::\n\nSuccess!\n\n::::\n:::::\n\n## Summary\n\n::: {.callout-tip}\n#### Key points\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n- We can reshape data, going from long to wide (and back).\n- Which format you use depends on the aim: consider how you'd plot data.\n- We can use `pivot_wider()` to create a wide-format data set.\n- We can use `pivot_longer()` to create a long-format data set.\n\n## Python\n\n- We can reshape data, going from long to wide (and back).\n- Which format you use depends on the aim: consider how you'd plot data.\n- We can use `.pivot()` to create a wide-format data set.\n- We can use `.melt()` to create a long-format data set.\n\n:::\n:::\n",
    "supporting": [
      "da4-09-reshaping-data_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}