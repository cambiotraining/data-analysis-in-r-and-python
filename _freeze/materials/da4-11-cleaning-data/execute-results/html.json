{
  "hash": "97e087a7674241e1d4413100534173f2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Clean, style & arrange\n---\n\n::: {.callout-tip}\n#### Learning objectives\n\n- \n:::\n\n\n## Context\nOften data is in a messy state before you can work with it. So, it is useful to know when and how to make changes to your data.\n\n## Section setup {#setup_grouped_operations}\n\n::: {.callout-note collapse=\"true\"}\n## Click to expand\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nWe'll continue this section with the script named `da4-11-cleaning-data.R`. If needed, add the following code to the top of your script and run it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# A collection of R packages designed for data science\nlibrary(tidyverse)\n\n# A package for cleaning up data\nlibrary(janitor)\n\nmessy_data <- read_csv(\"data/messy_data.csv\")\nsurveys <- read_csv(\"data/surveys.csv\")\nplot_types <- read_csv(\"data/plots.csv\")\n```\n:::\n\n\n## Python\n\nWe'll continue this section with the script named `da4-11-cleaning-data.py`. If needed, add the following code to the top of your script and run it.\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# A Python data analysis and manipulation tool\nimport pandas as pd\n\n# Python equivalent of `ggplot2`\nfrom plotnine import *\n\n# A package for cleaning up data\nimport janitor\n\nmessy_data = pd.read_csv(\"data/messy_data.csv\")\nsurveys = pd.read_csv(\"data/surveys.csv\")\nplot_types = pd.read_csv(\"data/plots.csv\")\n```\n:::\n\n\n:::\n:::\n\n## Cleaning data\n\nPerhaps it's not the most glamorous part of data analysis, but it is a very important one: cleaning data. If you need motivation for it, just think of the amount of time you can save yourself by recording your data consistently and correctly in the first place.\n\nIn the next few sections we'll go through some (very) common messy data issues you're likely to come across. We will revisit some of our previous data sets, but will mostly illustrate things using the `messy` data set. This data set has been synthesised for this exact purpose, so it's over-the-top bad. If you ever come across a real data set that looks like this, then a stern word with that researcher is in order!\n\nWe'll read in the data and take it from there:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmessy_data <- read_csv(\"data/messy_data.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 100 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): ID, Age, Gender, Score, country, employed.or.not, notes\ndbl (1): Income.in.GBP\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmessy_data = pd.read_csv(\"data/messy_data.csv\")\n```\n:::\n\n\n:::\n\n### Variable naming\n\nThe `messy` data set has many different issues with it. One of the issues is that the column headers are not consistent. This is an issue that you'll come across on a regular basis, since people have their own style (usually an inconsistent one!).\n\nIn both R and Python we have access to a \"janitor\" package ([`janitor`](https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html) in R and [`pyjanitor`](https://pypi.org/project/pyjanitor/) in Python). These are fantastic packages that can save you tons of time. \nHere we'll just use one of the functions: `clean_names()`.\n\nFirst, let's see what we're dealing with.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmessy_data |> \n  colnames()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"ID\"              \"Age\"             \"Gender\"          \"Score\"          \n[5] \"Income.in.GBP\"   \"country\"         \"employed.or.not\" \"notes\"          \n```\n\n\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmessy_data.columns.tolist()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n['ID', 'Age', 'Gender', 'Score', 'Income.in.GBP', 'country', 'employed.or.not', 'notes']\n```\n\n\n:::\n:::\n\n\n:::\n\nThat's not ideal. There is inconsistency in the use of capitalisation and there are full stops in the column names.\n\nNow, let's see what the `clean_names()` function makes of all of this (without updating the names just yet).\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmessy_data |> \n  clean_names() |> \n  colnames()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"id\"              \"age\"             \"gender\"          \"score\"          \n[5] \"income_in_gbp\"   \"country\"         \"employed_or_not\" \"notes\"          \n```\n\n\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(messy_data           # data\n  .clean_names()      # clean column names\n  .columns.tolist())  # put column names in list\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n['id', 'age', 'gender', 'score', 'income_in_gbp', 'country', 'employed_or_not', 'notes']\n```\n\n\n:::\n:::\n\n\n:::\n\nWe can see that the column names are now consistently lowercase and that the full stop `.` in the names have been replaced with `_` underscores.\n\nI'm happy with that, so I'll assign those new names to the data.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmessy_data <- messy_data |>\n  clean_names()\n```\n:::\n\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmessy_data = messy_data.clean_names()\n```\n:::\n\n\n:::\n\n### Adjusting numbers\n\nIn the [joining section](#setup_joins) we saw that it wasn't great practice to just use numbers to indicate `plot_id`, since they obviously have no numerical value, but instead define a category. This is something that often occurs, so it's useful to know how to be able to format them differently.\n\nFor example, we could encode them in the format `plot_xxx` where `xxx` is a number with leading zeros (so that it sorts nicely).\n\nWe can do that as follows:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_types |> \n  mutate(plot_id = paste0(\"plot_\", sprintf(\"%03d\", plot_id)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 2\n  plot_id  plot_type                \n  <chr>    <chr>                    \n1 plot_001 Spectab exclosure        \n2 plot_002 Control                  \n3 plot_003 Long-term Krat Exclosure \n4 plot_004 Rodent Exclosure         \n5 plot_005 Short-term Krat Exclosure\n```\n\n\n:::\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n## Alternative: using the `stringr` package\n\nThe `stringr` package is part of `tidyverse` and has a whole range of functions that allow you to change strings (text). The equivalent of the code above would be:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_types |> \n  mutate(plot_id = str_c(\"plot_\", str_pad(plot_id, width = 3, pad = \"0\")))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 2\n  plot_id  plot_type                \n  <chr>    <chr>                    \n1 plot_001 Spectab exclosure        \n2 plot_002 Control                  \n3 plot_003 Long-term Krat Exclosure \n4 plot_004 Rodent Exclosure         \n5 plot_005 Short-term Krat Exclosure\n```\n\n\n:::\n:::\n\n\nYou can read this as: \"Use `mutate()` to update the `plot_id` column, where (`=`) the contents of `plot_id` is a combined string (`str_c`) containing the text `\"plot_` and we pad out (`str_pad`) `plot_id` so it's 3 digits wide (`width = 3`) and we pad out with `\"0\"` (`pad = \"0\"`).\"\n\n:::\n\nIf you wanted to update the column, just add `plot_types <-` in front of this!\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nplot_types[\"plot_id\"].apply(\n    lambda x: f\"plot_{x:03d}\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0    plot_001\n1    plot_002\n2    plot_003\n3    plot_004\n4    plot_005\nName: plot_id, dtype: object\n```\n\n\n:::\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n## Alternative: using `.zfill()`\n\nIf you're not keen on this method using the `lambda x:` approach, you can use `.zfill`:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\"plot_\" + plot_types[\"plot_id\"].astype(str).str.zfill(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0    plot_001\n1    plot_002\n2    plot_003\n3    plot_004\n4    plot_005\nName: plot_id, dtype: object\n```\n\n\n:::\n:::\n\n\nYou can read this as: \"Take the `plot_id` column from `plot_types` (`plot_types[\"plot_id\"]`) and update it (`=`) with a combination of the text `plot_` (`\"plot_\"`) and the value of `plot_types[\"plot_id\"]`, which needs to be converted to a string (`.astype(str)`) before we can fill it with zeros up to a maximum of 3 digits (`.str.zfill(3)`).\"\n:::\n\nIf you wanted to update the column, just add `plot_types[\"plot_id\"] =` in front of this!\n\n:::\n\nNote: this means that you would also have to change the `plot_id` column values in the `surveys` data set, if you wanted to combine the data from these tables!\n\n### Encoding issues\n\nIn the `messy_data` data set it's not just the column names that are an issue. There are quite a few different encoding issues. We will address several of them now, but some of these you'll investigate later in the exercises.\n\n| Variable          | Problem(s)                                                                 |\n|-------------------|----------------------------------------------------------------------------|\n| `id`              | Clean — serves as a unique identifier                                      |\n| `age`             | (to investigate later) |\n| `gender`          | (to investigate later) |\n| `score`           | Numeric-like variable contains text entries: `\"five\"`, `\"high\"`, `NA`      |\n| `income_gbp`      | (to investigate later)                   |\n| `country`         | Inconsistent naming for UK: `\"UK\"`, `\"U.K.\"`, `\"United Kingdom\"`, `\"United kingdom\"`, `NA` |\n| `employed_or_not` | Inconsistent boolean values: `\"yes\"`, `\"y\"`, `\"TRUE\"`, `\"n\"`, `NA`, etc. |\n| `notes`           | Free-text notes with mixed missing indicators: `\"N/A\"`, `\"\"`, `\"none\"`, `NA` |\n\nLet's focus on the `country` column, which is a classical case of \"different people have different ways of encoding the same thing\".\n\nFirst, we check what entries we have in this column. Apart from just showing the different types of entries, we're also looking at how many times they occur.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmessy_data |> \n  count(country)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 2\n  country            n\n  <chr>          <int>\n1 U.K.              18\n2 UK                24\n3 United Kingdom    19\n4 United kingdom    20\n5 <NA>              19\n```\n\n\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(messy_data[\"country\"]\n  .value_counts(dropna = False)\n  .reset_index(name = \"n\")\n  .rename(columns = {\"index\": \"country\"}))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          country   n\n0              UK  24\n1  United kingdom  20\n2             NaN  19\n3  United Kingdom  19\n4            U.K.  18\n```\n\n\n:::\n:::\n\n\n:::\n\nWe've got quite some variation going on here. A convenient way of addressing this is to create a list of substitutions and then apply that to the data. This makes it easier in the future if you get more variations that you need to update.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\nIn R we have the `case_when()` function, which can help you do exactly that. It's more general though: it allows you to re-encode values based on conditions. So, before we apply it to our data, let's go through a simplified example.\n\n::: {.callout-tip}\n## Using `case_when()` for recoding values\nIt works in this way:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. create some dummy data\ndf <- tibble(score = c(45, 67, 82, 90, 55))\n\n# 2. recode the values\ndf <- df |> \n  mutate(performance = case_when(\n    score < 60               ~ \"fail\",\n    score >= 60 & score < 80 ~ \"pass\",\n    TRUE                     ~ \"excellent\"\n  ))\n\n# 3. show the result\ndf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 2\n  score performance\n  <dbl> <chr>      \n1    45 fail       \n2    67 pass       \n3    82 excellent  \n4    90 excellent  \n5    55 fail       \n```\n\n\n:::\n:::\n\n\nIn the mini-example above we create a simple data set with one column: `score`. There are 5 values in this column. We now want to assign a `performance` value to it, which will differ based on the score.\n\nThe `case_when()` function goes through each possible defined comparison (e.g. `score < 60`, `...`) and then assigns the value based on that (`~  \"fail\"`). We put the whole thing in a `mutate()` because we are creating a new column: `performance`.\n\nAt the end of the `case_when()` we have `TRUE ~ \"excellent`. The `TRUE ~` designation means: \"for everything else do...\".\n\n:::\n\nLet's apply this to our `messy_data`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmessy_data <- messy_data |> \n  mutate(country = case_when(\n    country %in% c(\"United kingdom\", \"U.K.\", \"UK\") ~ \"United Kingdom\",\n    TRUE ~ country\n  ))\n```\n:::\n\n\n1. `country = `indicates that we are updating our `country` column.\n2. `country %in% c(\"United kingdom\", \"U.K.\", \"UK\")` says, for each value in `country`, compare it to the values within `c()`\n3. `~ \"United Kingdom\"` if it finds it, replace it with `\"United Kingdom\"\n4. `TRUE ~ country` otherwise, leave it unchanged (including the missing values)\n\n## Python\n\nLet's apply this to our `messy_data`.\n\nFirst we create a \"translation\" table: which values do we want to re-encode and how?\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Define standard mapping for inconsistent names\ncountry_map = {\n    \"United kingdom\": \"United Kingdom\",\n    \"U.K.\": \"United Kingdom\",\n    \"UK\": \"United Kingdom\"\n    # Add more variations if needed\n}\n```\n:::\n\n\nNext, we apply this to our data:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Update the country names\nmessy_data[\"country\"] = (\n    messy_data[\"country\"]\n    .replace(country_map))\n```\n:::\n\n:::\n\nWe can view the end result:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmessy_data |> \n  count(country)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  country            n\n  <chr>          <int>\n1 United Kingdom    81\n2 <NA>              19\n```\n\n\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\ncounts = (\n    messy_data\n    .groupby(\"country\")\n    .size()\n    .reset_index(name = \"n\")\n)\n\ncounts\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          country   n\n0  United Kingdom  81\n```\n\n\n:::\n:::\n\n\n:::\n\n### Boolean values\nWe have a column `employed_or_not`, which contains information on the employment status of each person. This is encoded inconsistently, as `\"yes`, `\"y\"`, `\"TRUE\"`, ...\n\nApart from being consistent, it's useful to keep columns that can only have 1 of 3 value (true, false, missing) as a boolean. This makes it easier to filter and tally contents than if we'd encode it as text.\n\nLet's tackle this issue in a similar approach as above. First, let's see what we're dealing with here, by looking up the column types and the contents of `employed_or_not`.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(messy_data$employed_or_not)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"character\"\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmessy_data |>\n  count(employed_or_not)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 × 2\n  employed_or_not     n\n  <chr>           <int>\n1 FALSE               9\n2 TRUE               15\n3 n                  14\n4 no                 17\n5 y                  15\n6 yes                12\n7 <NA>               18\n```\n\n\n:::\n:::\n\n\nWe can see that the column is viewed as a `\"chr\"` or character column.\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmessy_data[\"employed_or_not\"].dtype\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ndtype('O')\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n(messy_data[\"employed_or_not\"]\n  .value_counts(dropna = False)\n  .reset_index(name = \"n\")\n  .rename(columns = {\"index\": \"employed_or_not\"}))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  employed_or_not   n\n0             NaN  18\n1              no  17\n2               y  15\n3            TRUE  15\n4               n  14\n5             yes  12\n6           FALSE   9\n```\n\n\n:::\n:::\n\n\nWe can see that the column is viewed as an `object` type (`'O'`). This type usually holds text, but can also be used for a mixture of Python objects.\n:::\n\nThe reason why we end up with a generic data type is because there is a mixture of data in the column. Let's fixed that.\n\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmessy_data <- messy_data |> \n  mutate(employed_or_not = case_when(\n    employed_or_not %in% c(\"no\", \"n\") ~ \"FALSE\",\n    employed_or_not %in% c(\"yes\", \"y\") ~ \"TRUE\",\n    TRUE ~ employed_or_not\n  ))\n```\n:::\n\n\nLet's count again:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmessy_data |> \n  count(employed_or_not)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 2\n  employed_or_not     n\n  <chr>           <int>\n1 FALSE              40\n2 TRUE               42\n3 <NA>               18\n```\n\n\n:::\n:::\n\n\nBut the `employed_or_not` column is still viewed as `character`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(messy_data$employed_or_not)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"character\"\n```\n\n\n:::\n:::\n\n\nSo, we need to force it to view it as such.\n\nTo make it a boolean / logical column, we use the `as.logical()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmessy_data <- messy_data |> \n  mutate(employed_or_not = as.logical(employed_or_not))\n```\n:::\n\n\nWe check one last time:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(messy_data$employed_or_not)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"logical\"\n```\n\n\n:::\n:::\n\n\n## Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Define standard mapping for inconsistent names\nemployment_map = {\n    \"no\": \"False\",\n    \"n\": \"False\",\n    \"yes\": \"True\",\n    \"y\": \"True\"\n    # Add more variations if needed\n}\n```\n:::\n\n\nNext, we apply this to our data:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Update the country names\nmessy_data[\"employed_or_not\"] = (\n    messy_data[\"employed_or_not\"]\n    .replace(employment_map))\n```\n:::\n\n\nWe count again to check what has happened:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ncounts = (\n    messy_data\n    .groupby(\"employed_or_not\", dropna = False)\n    .size()\n    .reset_index(name = \"n\")\n)\n\ncounts\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  employed_or_not   n\n0           FALSE   9\n1           False  31\n2            TRUE  15\n3            True  27\n4             NaN  18\n```\n\n\n:::\n:::\n\n\nThis still shows a difference between `FALSE` and `False`, and `TRUE` and `True`. That's because the all-caps words are interpreted as text. In fact, *all* of them are viewed as text, because we used `\" \"` in our mapping.\n\nPython's boolean phrases are `True` and `False`, so we need to adjust that.\n\nTo do this, we first convert all the values to lower case with `.str.lower()`, and then convert those values to boolean (without `\" \"`). Lastly, we convert the column to `\"boolean\"`. We need to do that last step, because we have missing data. If we didn't, then Python would keep all the contents as text.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmessy_data[\"employed_or_not\"] = (\n    messy_data[\"employed_or_not\"]\n    .str.lower()\n    .map({\"true\": True, \"false\": False})\n    .astype(\"boolean\")     # convert to boolean type\n)\n```\n:::\n\n\nWe can see that we only have `True`, `False` or `<NA>`.\n\n\n::: {.cell}\n\n```{.python .cell-code}\ncounts = (\n    messy_data\n    .groupby(\"employed_or_not\", dropna = False)\n    .size()\n    .reset_index(name = \"n\")\n)\n\ncounts\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   employed_or_not   n\n0            False  40\n1             True  42\n2             <NA>  18\n```\n\n\n:::\n:::\n\n\nAnd our data type is now correct.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmessy_data[\"employed_or_not\"].dtype\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBooleanDtype\n```\n\n\n:::\n:::\n\n\n:::\n\nSuccess!\n\n## Summary\n\n::: {.callout-tip}\n#### Key points\n\n- \n:::\n",
    "supporting": [
      "da4-11-cleaning-data_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}