---
title: Manipulating rows
---

::: {.callout-tip}
#### Learning objectives

- Learn to order and arrange rows.
- Be able to find and retain unique rows.
- Understand how logical operators are used.
- Implement conditional statements to filter specific data.
- Be able to identify and decide how to deal with missing data.

:::


## Context

Data sets can contain large quantities of observations. Often we are only interested in part of the data at a given time. We can deal with this by manipulating rows.

## Section setup {#setup_manipulating_rows}

::: {.panel-tabset group="language"}
## R

We'll continue this section with the script named `03_session`. If needed, add the following code to the top of your script and run it.

In this section we will use a new package, called `naniar`, to visualise where we have missing data. Install it as follows:

```{r}
#| eval: false
# install if needed
install.packages("naniar")
```

```{r}
#| message: false
# A collection of R packages designed for data science
library(tidyverse)

# Package to visualise missing data
library(naniar)

surveys <- read_csv("data/surveys.csv")
```

## Python

We'll continue this section with the Notebook named `03_session`. Add the following code to the first cell and run it.

We'll use a new package, so install if needed from the terminal:

```{bash}
#| eval: false
mamba install conda-forge::missingno
```

Then, if needed, add the following code to the top of your script and run it.

```{python}
# A Python data analysis and manipulation tool
import pandas as pd

# Python equivalent of `ggplot2`
from plotnine import *

# If using seaborn for plotting
import seaborn as sns
import matplotlib.pyplot as plt

# Load missingno
import missingno as msno

surveys = pd.read_csv("data/surveys.csv")
```

:::


## Manipulation of observations

### Ordering rows
We often want to order data in a certain way, for example ordering by date or in alphabetically. The example below illustrates how we would order data based on `weight`:

::: {.carousel data-caption="Ordering by weight in ascending order (click to toggle)."}

![](images/manipulation-order_main.png)
![](images/manipulation-order_weight.png)
:::

Let's illustrate this with the `surveys` data set, arranging the data based on `year`.

::: {.panel-tabset group="language"}
## R

```{r}
surveys |> 
  arrange(year)
```

If we'd want to arrange the data in *descending* order (most recent to oldest), we would employ the `desc()` helper function:

```{r}
surveys |> 
  arrange(desc(year))
```

We can read that bit of code as "take the `surveys` data set, send it to the `arrange()` function and ask it to arrange the data in descending order (using `desc()`) based on the `year` column".

We can also combine this approach with multiple variables, for example arranging data based on descending year *and* (ascending) hindfoot length:

```{r}
surveys |> 
  arrange(desc(year), hindfoot_length)
```

## Python

```{python}
surveys.sort_values(by = "year")
```

If we'd want to arrange the data in *descending* order (most recent to oldest), we would specify this with the `ascending = False` argument:

```{python}
surveys.sort_values(by = "year", ascending = False)
```

We can also combine this approach with multiple variables, for example arranging data based on descending year *and* (ascending) hindfoot length:

```{python}
surveys.sort_values(
    by = ["year", "hindfoot_length"],
    ascending = [False, True]
)
```

:::

### Finding unique values

Sometimes it is useful to retain rows with unique combinations of some of our variables (i.e. remove any duplicated rows). 

::: {.panel-tabset group="language"}
## R

This can be done with the `distinct()` function.

```{r}
surveys |> 
  distinct(species_id, year)
```


## Python

We can do this by specifying which column we'd like to get the unique values from (here, we're using `species_id` and `year` as an example). We then use `.drop_duplicates()` to remove all the duplicate values:

```{python}
surveys[["species_id", "year"]].drop_duplicates()
```

:::

### Filtering by condition
Often we want to filter our data based on specific conditions / properties in the data. For example, in our data set you might want to filter for certain years, a specific weight range or only get all the observations for the first 100 record IDs.

Before we delve into this, it is important to understand that when we set a condition like above, the output 
is a _logical vector_. Let's see an example using a small vector.

::: {.panel-tabset group="language"}
## R

```{r}
some_years <- c(1985, 1990, 1999, 1995, 2010, 2000)
some_years < 2000
```

## Python

For this example we'll keep using `pandas`, for consistency. Since we're only dealing with a simple, one-dimensional bunch of data, we create a `Series`:

```{python}
some_years = pd.Series([1985, 1990, 1999, 1995, 2010, 2000])
result = some_years < 2000

result
```

:::

It is possible to combine several conditions by using the _logical operators_ 
`&` (AND) and `|` (OR). For example, if we wanted the years between 1990 and 2000:

::: {.panel-tabset group="language"}
## R

```{r}
# both conditions have to be true
some_years > 1990 & some_years < 2000
```

And if we wanted the years below 1990 or above 2000, then:

```{r}
# only one or the other of the conditions has to be true
some_years < 1990 | some_years > 2000
```

## Python

```{python}
result = (some_years > 1990) & (some_years < 2000)

result
```

And if we wanted the years below 1990 or above 2000, then:

```{python}
result = (some_years < 1990) | (some_years > 2000)

result
```

:::

This concept is also applied to tables. We could filter across all rows in the `surveys` data set, for a `hindfoot_length` of larger than 31 mm:

![The logic behind filtering: for each row the condition is checked (here: `hindfoot_length > 31`). If the outcome is `TRUE` then the row is returned.](images/manipulation-filter_rows.png){#fig-manipulation_filter_rows}

We could then do this as follows:

::: {.panel-tabset group="language"}
## R

```{r}
surveys |> 
  filter(hindfoot_length > 31)
```

## Python

```{python}
surveys[surveys["hindfoot_length"] > 31]
```

Another option would be to use the `.query()` function. This is functionally equivalent, but a bit easier to read.

```{python}
surveys.query("hindfoot_length > 31")
```

:::

This then only keeps the observations where `hindfoot_length > 31`, in this case 
`r surveys |> filter(hindfoot_length > 31) |> nrow()` observations.

::: {.callout-important}
## Conditional  operators

::: {.panel-tabset group="language"}
## R

To set filtering conditions, use the following _relational operators_:
 
- `>` is greater than
- `>=` is greater than or equal to
- `<` is less than
- `<=` is less than or equal to
- `==` is equal to
- `!=` is different from
- `%in%` is contained in

To combine conditions, use the following _logical operators_:

- `&` AND
- `|` OR
 
Some functions return logical results and can be used in filtering operations:
 
- `is.na(x)` returns _TRUE_ if a value in _x_ is missing

The `!` can be used to negate a logical condition:

- `!is.na(x)` returns _TRUE_ if a value in _x_ is NOT missing
- `!(x %in% y)` returns _TRUE_ if a value in _x_ is NOT present in _y_

## Python

To set filtering conditions, use the following _relational operators_:
 
- `>` is greater than
- `>=` is greater than or equal to
- `<` is less than
- `<=` is less than or equal to
- `==` is equal to
- `!=` is different from
- `.isin([...])` is contained in

To combine conditions, use the following _logical operators_:

- `&` AND
- `|` OR
 
Some functions return logical results and can be used in filtering operations:
 
- `df["x"].isna()` returns _True_ if a value in _x_ is missing

The `~` (bitwise NOT) can be used to negate a logical condition:

- `~df["x"].isna()` returns _True_ if a value in _x_ is NOT missing
- `~df["x"].isin(["y"])` returns _True_ if a value in _x_ is NOT present in `"y"`
:::

:::

### Missing data revisited {#missingdata-revisited}

It's important to carefully consider how to deal with missing data, as we
[have previously seen](#missing-data). It's easy enough to filter out all rows that contain missing data, however this is rarely the best course of action, because you might accidentally throw out useful data in columns that you'll need later.

Furthermore, it's often a good idea to see if there is any **structure** in your missing data. Maybe certain variables are consistently absent, which could tell you something about your data.

::: {.panel-tabset group="language"}

## R

We could filter out all the missing `weight` values as follows:

```{r}
surveys |> 
  filter(!is.na(weight))
```

## Python

```{python}
surveys.dropna(subset=["weight"])
```

:::

::: {.panel-tabset group="language"}

## R

We can combine this for multiple columns:

```{r}
surveys |> 
  filter(!is.na(weight) & !is.na(hindfoot_length))
```

## Python

```{python}
surveys.dropna(subset = ["weight", "hindfoot_length"])
```

:::

We can also combine that with other filters.

::: {.panel-tabset group="language"}

## R

```{r}
surveys |> 
  filter(!is.na(weight) & !is.na(hindfoot_length)) |> 
  filter(hindfoot_length > 40)
```

## Python

To do this, we might prefer to use a slightly syntax: the `.notna()`. This allows us to chain operations a bit cleaner, making our code easier to read:

```{python}
surveys[
    (surveys["weight"].notna()) &
    (surveys["hindfoot_length"].notna()) &
    (surveys["hindfoot_length"] > 40)
]

```
:::

Often it's not that easy to get a sense of how missing data are distributed in the data set. We can use summary statistics and visualisations to get a better sense.

::: {.panel-tabset group="language"}

## R

The easiest way of getting some numbers on the missing data is by using the `summary()` function, which will report the number of `NA`'s for each column (for example: see the `hindfoot_length` column):

```{r}
summary(surveys)
```

Often it's nice to visualise where your missing values are, to see if there are any patterns that are obvious. There are several packages in R that can do this, of which `naniar` is one.

```{r}
#| eval: false
# install if needed
install.packages("naniar")

# load the library
library(naniar)
```

```{r}
# visualise missing data
vis_miss(surveys)
```

## Python

The easiest way of counting the number of missing values in Python is by combining `.isna()` and `.sum()`:

```{python}
# count missing values
surveys.isna().sum()
```

Often it's nice to visualise where your missing values are, to see if there are any patterns that are obvious. There are several packages in Python that can do this, of which `missingno` is one.

```{python}
#| eval: false
import missingno as msno
```

```{python}
# visual matrix
msno.matrix(surveys)
```

:::

## Exercises

### Filtering data: `infections` {#sec-exr_filter}

::::: {#ex-title .callout-exercise}
#### Filtering data

{{< level 2 >}}

For this exercise we'll be using the data from `data/infections.csv`.

1. Filter for all the rows where the infection type is `bacterial` and the patient was not admitted to the ICU (Intensive Care Unit).
2. Filter for all the rows where the patient is older than 65 and CRP levels are either between 10-15 or 50-60.

:::: {.callout-answer collapse="true"}

First we load the data.

::: {.panel-tabset group="language"}
## R

```{r}
#| message: false
infections <- read_csv("data/infections.csv")
```


## Python

```{python}
infections = pd.read_csv("data/infections.csv")
```

:::

#### 1. Bacterial and non-ICU

To get the data we want, we need to filter for rows where:

1. `infection_type` contains the text `"bacterial"`
2. `icu_admission` is equal to `TRUE` (R) / `True` (Python)

::: {.panel-tabset group="language"}
## R

```{r}
infections |> 
  filter(infection_type == "bacterial" & icu_admission == FALSE)
```

## Python

```{python}
(
  infections
  .query("infection_type == 'bacterial' and icu_admission == False")
)
```

:::

#### 2. Patients in 65+ group with certain CRP levels

Here we need to filter for three things:

1. `age_group` values of `"65+"` (string/text)
2. `crp_level > 10` and `crp_level < 15`
3. `crp_level > 50` and `crp_level < 60`

::: {.panel-tabset group="language"}
## R

```{r}
infections |> 
  filter(age_group == "65+") |> 
  filter(crp_level > 10 & crp_level < 15 |
           crp_level > 50 & crp_level < 60)
```


## Python

Using `.query()`:

```{python}
(
  infections
  .query(
    "age_group == '65+' and ((10 < crp_level < 15) or (50 < crp_level < 60))")
)
```

We can also use a more explicit version using normal subsetting (which becomes quite convoluted, quite quickly!):

```{python}
#| echo: false
(
  infections
  .loc[
    (infections["age_group"] == "65+") &
    (
      ((infections["crp_level"] > 10) & (infections["crp_level"] < 15)) |
      ((infections["crp_level"] > 50) & (infections["crp_level"] < 60))
      )
    ]
)

```

:::

::::
:::::

## Summary

::: {.callout-tip}
#### Key points

::: {.panel-tabset group="language"}

## R

- We use the `arrange()` function to order data, and can reverse the order using `desc()`.
- Unique rows can be retained with `distinct()`.
- We use `filter()` to choose rows based on conditions.
- Conditions can be set using several operators: `>`, `>=`, `<`, `<=`, `==`, `!=`, `%in%`.
- Conditions can be combined using `&` (AND) and `|` (OR).
- The function `is.na()` can be used to identify missing values. It can be negated as `!is.na()` to find non-missing values.
- We can visualise missing data using the `vis_miss()` function from the `naniar` package.

## Python

- We can use the `.sort_values()` method to order data, specifying the `ascending =` argument as `True` or `False` to control the order.
- The `.drop_duplicates()` method allows us to retain unique rows.
- We use subsetting (e.g. `surveys[surveys["hindfoot_length"] > 31]`) together with conditions to filter data.
-- Conditions can be set using several operators: `>`, `>=`, `<`, `<=`, `==`, `!=`, `.isin([...])`.
- Conditions can be combined using `&` (AND) and `|` (OR).
- The function `.isna()` can be used to identify missing values. It can be negated using `~` to find non-missing values (e.g. `surveys[~surveys["weight"].isna()]`.
- We can visualise missing data using the `msno.matrix` function from the `missingno` package.

:::

:::
