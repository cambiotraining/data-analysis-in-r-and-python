---
title: Reshaping data
---

::: {.callout-tip}
#### Learning objectives

- Learn what long and wide data formats are.
- Be able to recognise when best to use each.
- Be able to switch from long to wide and back.
:::

## Context
So far, we have provided data in the most convenient format. In real life, this is of course not always the case, because people collect data in a format that works best for them - not the computer. So, sometimes we need to change the shape of our data, so we can calculate or visualise the data we'd like.

## Section setup {#setup_reshaping_data}

::: {.panel-tabset group="language"}
## R

We'll continue this section with the script named `04_session`. If needed, add the following code to the top of your script and run it.

```{r}
#| message: false
# A collection of R packages designed for data science
library(tidyverse)

surveys_join <- read_csv("data/surveys_join.csv")
```

## Python

We'll continue this section with the Notebook named `04_session`. Add the following code to the first cell and run it.

```{python}
# A Python data analysis and manipulation tool
import pandas as pd

# Python equivalent of `ggplot2`
from plotnine import *

# If using seaborn for plotting
import seaborn as sns
import matplotlib.pyplot as plt

surveys_join = pd.read_csv("data/surveys_join.csv")
```

:::

## Data reshaping

Let's look at a hypothetical data set, based on the type of variables we've come across in the `surveys` data.

![Wide and long data formats contain the same information](images/long_and_wide.png){#fig-long_wide}

The data that is present in both tables is the same - it's just encoded slightly differently.

1. The "long" format is where we have a column for each of the types of things we measured or recorded in our data. In other words, each variable has its own column.
2. The "wide" format occurs when we have data relating to the same measured thing in different columns. In this case, we have values related to our *metric* spread across multiple columns (a column each for a year).

::: {.callout-note}
## Wide or long?

Neither of these formats is necessarily more correct than the other: it will depend on what analysis you intend on doing. However, it is worth mentioning that the "long" format is often preferred, as it is clearer how many distinct types of variables we have in the data.

To figure out which format you might need, it may help to think of which visualisations you may want to build with `ggplot()` (or other packages, for that example). Taking the above example:

* If you were interested in looking at the change of `weight` across years for each individual, then the long format is more suitable to define each aesthetic of such a graph: `aes(x = year, y = weight, colour = record_id)`.
* If you were interested in the correlation of this metric between 2021 and 2022, then the wide format would be more suitable: `aes(x = yr_2021, y = yr_2022, colour = record_id)`.
:::

## From long to wide {#sec-long_to_wide}

Let's illustrate that with a dummy data set, called `surveys_join`. In this synthetic data set we have `weight` measurements for individuals across four years: 2021 - 2024. This means that there are four measurements for each `record_id`.

::: {.panel-tabset group="language"}
## R

```{r}
#| message: false
# Read in the data
surveys_join <- read_csv("data/surveys_join.csv")

# Look at the first few rows
head(surveys_join)
```

We can reshape our data from long to wide as follows, where I do *not* overwrite the existing data, but instead just pipe it through to the `head()` function, so we can see what the `pivot_wider()` function is doing:

```{r}
surveys_join |> 
  pivot_wider(names_from = "year",
              values_from = "weight",
              names_prefix = "yr_") |>
  head()
```

Let's unpack that a bit. 

The `pivot_wider()` function needs at least the first two arguments:

1. `names_from =` the column who's values we want to use for our new column names (`year`)
2. `values_from =` the column who's values we want to use to populate these new columns (`weight`)
3. `names_prefix =` a prefix for our column names (optional)

Here we also add `names_prefix = "yr_"`, otherwise the column names would contain only numbers and that's not very good programming habit.

Let's assign it to a new object and then visualise some of the data.

```{r}
surveys_wide <- surveys_join |> 
  pivot_wider(names_from = "year",
              values_from = "weight",
              names_prefix = "yr_")
```

## Python

```{python}
# Read in the data
surveys_join = pd.read_csv("data/surveys_join.csv")

# Look at the first few rows
surveys_join.head()
```

```{python}
surveys_wide = surveys_join.pivot(
    index = "record_id",
    columns = "year",
    values = "weight"
)

# Add 'yr_' prefix to year columns
surveys_wide.columns = [f"yr_{col}" for col in surveys_wide.columns]

# Reset index to make 'record_id' a column again
surveys_wide = surveys_wide.reset_index()

surveys_wide.head()
```


:::{.callout-note}
## More on adding the prefix

We explain the `f` notation in more detail in @sec-variable_naming. Briefly, in the example above we take all the column names (`surveys_wide.columns` and for each column (`for col in`) we add the `yr_` prefix.
:::

:::

We can then use this to visualise possible relationships between the different years:

::: {.panel-tabset group="language"}
## R

```{r}
#| label: fig-weight_2122
#| fig-cap: "Scatterplot of `weight` for 2021 and 2022"
ggplot(surveys_wide, aes(x = yr_2021, y = yr_2022)) +
  geom_point()
```

If you'd be interested in comparisons across all years, you'd have to use the original, long format because there isn't a single column in the wide table that contains all of the year information.

```{r}
#| label: fig-weight_by_year
#| fig-cap: "Boxplot of `weight` for 2021 - 2024"
ggplot(surveys_join, aes(x = factor(year), y =  weight)) +
  geom_boxplot()
```

## Python

```{python}
#| results: hide
#| label: fig-weight_2122_py
#| fig-cap: "Scatterplot of `weight` for 2021 and 2022"

p = (ggplot(surveys_wide, aes(x = "yr_2021", y = "yr_2022")) +
    geom_point())
    
p.show()
```

::: {.callout-note collapse="true"}
## Seaborn equivalent

```{python}
#| results: hide
#| label: fig-weight_2122_seaborn
#| fig-cap: "Scatterplot of `weight` for 2021 and 2022"

sns.scatterplot(
    data = surveys_wide,
    x = "yr_2021",
    y = "yr_2022"
)

plt.title("Scatterplot of yr_2021 vs yr_2022")
plt.show()

```
:::

```{python}
#| results: hide
#| label: fig-weight_by_year_py
#| fig-cap: "Boxplot of `weight` for 2021 - 2024"
p = (ggplot(surveys_join, aes(x = "factor(year)", y = "weight")) +
    geom_boxplot())

p.show()
```

::: {.callout-note collapse="true"}
## Seaborn equivalent

```{python}
#| results: hide
#| label: fig-weight_by_year_seaborn
#| fig-cap: "Boxplot of `weight` for 2021 - 2024"

sns.boxplot(
    data = surveys_join,
    x = "year", # seaborn treats numeric as categorical automatically if discrete
    y = "weight"
)

plt.title("Weight by year (boxplot)")
plt.show()

```
:::

:::

## From wide to long
We can reshape our data from wide to long. This is more or less the inverse of what we did above.

::: {.panel-tabset group="language"}
## R

```{r}
surveys_wide |> 
  pivot_longer(cols = -record_id,
               names_to = "year",
               values_to = "weight",
               names_prefix = "yr_")
```

Here we use the following arguments:

1. `cols =` this tells `pivot_longer()` which columns to pivot - here we want to use all but the `record_id` column
2. `names_to =` the name of the column that gets to hold the column names (e.g. `yr_2021`, `yr_2022` ...)
3. `values_to =` the name of the column that will contain the measured values (here those are the `weight` measurements)
4. `names_prefix =` here we tell it that all column names have a prefix `yr_`, which then gets removed prior to populating the column

## Python

To go back to the long format, we use the `.melt()` function.

```{python}
surveys_long = surveys_wide.melt(
    id_vars = "record_id",            # columns to keep fixed
    var_name = "year",                # name of the new 'year' column
    value_name = "weight"             # name of the new 'weight' column
)

surveys_long.head()
```

This uses the following arguments:

1. `id_vars =` this tells it what the `id` column is - `record_id` in our case, which does not get pivoted.
2. `var_name =` the name of the column that gets to hold the column names (e.g. `yr_2021`, `yr_2022` ...)
3. `value_name =` the name of the column that will contain the measured values (here those are the `weight` measurements)

This then creates a column `year` that contains the values `yr_2021`, `yr_2022`, `...`, since we added the prefix. If we want to remove the prefix we can do the following:

```{python}
# Remove 'yr_' prefix and convert year to integer
surveys_long["year"] = surveys_long["year"].str.replace("yr_", "").astype(int)

surveys_long.head()
```

:::

## Exercises

### Reshaping: `auxin` {#sec-exr_reshape_auxin}

::::: {.callout-exercise #ex-reshape_auxin}
#### Reshaping data

{{< level 2 >}}

For this exercise we'll be using the data from `data/auxin.csv`.

These are synthetic data that measure the plant height of *Arabidopsis thaliana*, in different genotypes (variants of the same species, here: `control` and `mutant`). It measures the effect the plant hormone auxin has on the growth of these plants.

This is done across different auxin concentrations (`none`, `low`, `high`).

Please do the following:

1. Check the data structure.
2. Create a "wide" table where, for each `replicate_id` / `genotype` pair, we have a column for each auxin concentration category. The data in these columns should be the `plant_height` measurements.
3. Use this wide format to calculate the average plant height for each row.
4. Change the data back to "long" format & check if you have your original data back.

:::: {.callout-answer collapse="true"}
First, let's read in the data.

::: {.panel-tabset group="language"}
## R

```{r}
#| message: false
auxin <- read_csv("data/auxin.csv")
```


## Python

```{python}
auxin = pd.read_csv("data/auxin.csv")
```

:::

#### 1. Data structure

Before we make any changes, it's important to get a sense of how the data is currently shaped.

::: {.panel-tabset group="language"}
## R

```{r}
head(auxin)
```


## Python

```{python}
auxin.head()
```

:::

We have `r auxin |> distinct(replicate_id) |> nrow()` distinct `replicate_id` values, with at least `r auxin |> count(replicate_id) |> filter(n == min(n)) |> slice(1) |> pull(n)` and up to `r auxin |> count(replicate_id) |> filter(n == max(n)) |> slice(1) |> pull(n)` observations.

There are also three distinct concentration categories: `r auxin |> distinct(concentration) |> pull()`

:::{.callout-important}
Check this yourself!
:::

#### 2. From long to wide

So what we want to do is get a table where for each `replicate_id` and `genotype` combination we have a separate column for each `concentration` category. That would allow us, for example, to calculate the average plant height for each measurement across the different concentration types.

The data should look something like:

| replicate_id | genotype |  high |  low  |  none |
|--------------|----------|-------|-------|-------|
| 1            | control  |  31.7 |  38.5 |  42.7 |
| 2            | control  |  33.6 |  35.9 |  46.8 |
| 3            | control  |  31.3 |  38.4 |  42.8 |

So, let's do that.

::: {.panel-tabset group="language"}
## R

```{r}
auxin_wide <- pivot_wider(auxin,
            names_from = concentration,
            values_from = plant_height)

head(auxin_wide)
```


## Python

```{python}
auxin_wide = auxin.pivot(
    index = ["replicate_id", "genotype"],
    columns = "concentration",
    values = "plant_height"
).reset_index()

auxin_wide.head()
```

:::

#### 3. Calculating average `plant_height`

Having the data in this format allows us to do:

::: {.panel-tabset group="language"}
## R

```{r}
auxin_wide |> 
  mutate(avg_height = round((high + low + none) / 3, 1)) |> 
  head()
```

## Python

```{python}
auxin_wide.assign(
    avg_height = auxin_wide[["high", "low", "none"]] # select columns
    .mean(axis = 1)                                  # calculate mean
    .round(1)                                        # round to 1 decimal
).head()                                             # display first few rows
```

:::

#### 4. From wide to long

We can also revert back to our original "long" format data. The data then has its original shape back, which follows:

| replicate_id | genotype | concentration | plant_height |
|--------------|----------|---------------|--------------|
| 1            | control  | high          | 31.7         |
| 2            | control  | high          | 33.6         |
| 3            | control  | high          | 31.3         |

So, let's do that.

::: {.panel-tabset group="language"}
## R

```{r}
auxin_long <- pivot_longer(auxin_wide,
             cols = c("high", "low", "none"),
             names_to = "concentration",
             values_to = "plant_height")
```


## Python

```{python}
auxin_long = auxin_wide.melt(
    id_vars = ["replicate_id", "genotype"],  # columns to keep as identifiers
    value_vars = ["high", "low", "none"],    # columns to unpivot
    var_name = "concentration",              # new column for old column names
    value_name = "plant_height"              # new column for values
)
```

:::

However, the eagle-eyed among you might have noticed that there are more rows in our data than we started with:

::: {.panel-tabset group="language"}
## R

```{r}
nrow(auxin)
nrow(auxin_long)
```


## Python

```{python}
auxin.shape[0]      # original data
auxin_long.shape[0] # wide-and-back
```

:::

This is because in some of the `replicate_id` / `genotype` combinations there were no measured values for all three concentration types. This introduced missing values, which are then propagated when going back to a long format.

So, to deal with this, we can simply remove the values where the `plant_height` value is missing:

::: {.panel-tabset group="language"}
## R

```{r}
auxin_long <- pivot_longer(auxin_wide,
             cols = c("high", "low", "none"),
             names_to = "concentration",
             values_to = "plant_height",
             values_drop_na = TRUE)

nrow(auxin_long)
```

## Python

```{python}
auxin_long = (auxin_wide.melt(
    id_vars = ["replicate_id", "genotype"],  # columns to keep as identifiers
    value_vars = ["high", "low", "none"],    # columns to unpivot
    var_name = "concentration",              # new column for old column names
    value_name = "plant_height"              # new column for values
)
.dropna(subset = ["plant_height"])
)

auxin_long.shape[0]
```

:::

Success!

::::
:::::

## Summary

::: {.callout-tip}
#### Key points

::: {.panel-tabset group="language"}
## R

- We can reshape data, going from long to wide (and back).
- Which format you use depends on the aim: consider how you'd plot data.
- We can use `pivot_wider()` to create a wide-format data set.
- We can use `pivot_longer()` to create a long-format data set.

## Python

- We can reshape data, going from long to wide (and back).
- Which format you use depends on the aim: consider how you'd plot data.
- We can use `.pivot()` to create a wide-format data set.
- We can use `.melt()` to create a long-format data set.

:::
:::
