---
title: Grouped operations
---

::: {.callout-tip}
#### Learning objectives

- Learn how to use grouped operations in data analysis.
- Be able to distinguish between grouped summaries and other types of grouped operations.
:::


## Context

We’ve done different types of operations, all on the entire data set. Sometimes there is structure within the data, such as different groups (e.g. genotypes, patient cohorts, geographical areas etc). We might then want information on a group-by-group basis.

## Section setup {#setup_grouped_operations}

::: {.callout-note collapse="true"}
## Click to expand

::: {.panel-tabset group="language"}
## R

We'll continue this section with the script named `r paste0(intToUtf8(96), sub("\\..*$", ".R", knitr::current_input()), intToUtf8(96))`. If needed, add the following code to the top of your script and run it.

```{r}
#| message: false
# A collection of R packages designed for data science
library(tidyverse)

surveys <- read_csv("data/surveys.csv")
```

## Python

We'll continue this section with the script named `r paste0(intToUtf8(96), sub("\\..*$", ".py", knitr::current_input()), intToUtf8(96))`. If needed, add the following code to the top of your script and run it.

```{python}
# A Python data analysis and manipulation tool
import pandas as pd

# Python equivalent of `ggplot2`
from plotnine import *

surveys = pd.read_csv("data/surveys.csv")
```

:::
:::

## Split-apply-combine

Conceptually, this kind of operation can be referred to as split-apply-combine, because we split the data, apply some function and then combine the outcome.

Let's illustrate this with an example. @fig-groupby_table shows a hypothetical data set, where we have temperature and rainfall measurements for different cities.

![An example of a table with groups](images/groupby_table.png){#fig-groupby_table}

Let's assume we were interested in the average temperature for each city. We would have to do the following:

1. Split the data by `city`
2. Calculate the average `temperature`
3. Combine the outcome together in a new table

This is visualised in @fig-groupby_split.

![Split-apply-combine](images/groupby_split.png){#fig-groupby_split}

## Summary operations

Let's put this into practice with our data set.

### Summarising data

A common task in data analysis is to summarise variables to get the mean and the variation around it.

For example, let’s calculate what the mean and standard deviation are for `weight`.

::: {.panel-tabset group="language"}
## R

We can achieve this task using the `summarise()` function.

```{r}
surveys |> 
  summarise(weight_mean = mean(weight, na.rm  = TRUE),
            weight_sd = sd(weight, na.rm = TRUE))
```

A couple of things to notice:

The output of `summarise` is a new table, where each column is named according to the input to `summarise()`.

Within `summarise()` we should use functions for which the output is a single value.
Also notice that, above, we used the `na.rm` option within the summary functions, so that they ignored missing values when calculating the respective statistics.

## Python

:::

::: {.callout-tip}
## Summary functions

::: {.panel-tabset group="language"}
## R

There are many functions whose input is a vector (or a column in a table) and the output is a single number. Here are several common ones:

* `mean(x)` - arithmetic mean
* `median(x)` - median
* `sd(x)` - standard deviation
* `var(x)` - variance
* `IQR(x)` - interquartile range
* `mad(x)` - median absolute deviation
* `min(x)` and `max(x)` - minimum and maximum
* `quantile(x, probs = 0.75)` - [quantile](https://simple.wikipedia.org/wiki/Quantile) (use the `probs` option to set the quantile of your choosing)
* `sum(x)` - addition of all values in `x`
* `n_distinct(x)` (from `dplyr`) - the number of distinct values in the vector `x`

All of these have the option `na.rm`, which tells the function remove missing values before doing the calculation.

## Python

:::
:::

### Grouped summaries

In most cases we want to calculate summary statistics across groups of our data. 

::: {.panel-tabset group="language"}
## R

We can achieve this by combining `summarise()` with the `group_by()` function. For example, let’s modify the previous example to calculate the summary for each `sex` group:

```{r}
surveys |> 
  group_by(sex) |> 
  summarise(weight_mean = mean(weight, na.rm  = TRUE),
            weight_sd = sd(weight, na.rm = TRUE))
```

The table output now includes both the columns we defined within `summarise()` as well as the grouping columns defined within `group_by()`.

## Python
:::

## Counting data

Counting or tallying data is an extremely useful way of getting to know your data better.

### Simple counting

::: {.panel-tabset group="language"}
## R

We can use the `count()` function from `dplyr` to count data. It always returns the number of rows it counts.

For example, this gives us the total number of observations (rows) in our data set:

```{r}
count(surveys)
```

We can also do that using conditional statements:

```{r}
# count the observations from the year 1982
surveys |> 
  filter(year == 1982) |> 
  count()
```


## Python

:::

### Counting by group

Counting really comes into its own when we're combining this with some grouping. For example, we might be interested in the number of observations for each year.

::: {.panel-tabset group="language"}
## R

```{r}
surveys |> 
  count(year)
```

We can also easily visualise this (we can pipe straight into `ggplot()`). We use `geom_col()` to create a bar chart of the number of observations per year. We count by `sex` and use this variable to fill the colour of the bars.

```{r}
surveys |> 
  count(sex, year) |> 
  ggplot(aes(x = year, y = n, fill = sex)) +
  geom_col()
```

::: {.callout-important}
## Counting within a summary pipeline

Often we want to do counting when we're creating summaries. The `count()` function can't be used within `summarise()`, but there is a special helper function called `n()`. Look at the following example, where we group by year, filter the data, create some summary statistic and also count the number of rows within each group.

```{r}
surveys |> 
  group_by(year) |>                                   # group the data
  filter(year %in% c(1981, 1982)) |>                  # filter a subset of years
  summarise(mean_weight = mean(weight, na.rm = TRUE), # calculate mean weight
            n_obs = n()) |>                           # number of rows
  ungroup()                                           # drop the grouping
```

:::

## Python

:::

### Counting missing data

Oh, missing data! How we've missed you. For something that isn't there, is has quite the presence. But, it is an important consideration in data analysis. We've [already seen](#missingdata-revisited) how we can remove missing data from and also explored ways to visualise them.

::: {.panel-tabset group="language"}
## R

We have seen how to use the `summary()` function to find missing values. Here we'll see (even more) ways to tally them.

We can use the `is.na()` function to great effect, within a `summarise()` pipeline. We can negate with `!is.na()` to find non-missing values. Again, using the `sum()` function then enables us to tally how many missing / non-missing values there are.

```{r}
surveys |> 
  summarise(obs_present = sum(!is.na(species_id)),    # count non-missing data
            obs_absent = sum(is.na(species_id)),      # count missing data
            n_obs = n(),                              # total number of rows
            precentage_absent = 
              (obs_absent / n_obs) * 100) |>          # percentage of missing data
  ungroup()
```

## Python

:::

## Grouped operations

### Grouped filters
Sometimes it can be really handy to filter data, by group. In our `surveys` data, for example, you might be interested to find out what the minimum `weight` value is for each `year`. We can do that as follows: 

::: {.panel-tabset group="language"}
## R

```{r}
surveys |> 
  group_by(year) |> 
  filter(weight == min(weight, na.rm = TRUE)) |> 
  ungroup()
```

You can see that this outputs the minimum value, but if there are multiple entries for each year (such as in `1978`), multiple rows returned. If we only wanted to get a single row per minimum value, per year, then we can use `slice(1)`. This slices the first row of each group:

```{r}
surveys |> 
  group_by(year) |> 
  filter(weight == min(weight, na.rm = TRUE)) |> 
  slice(1) |> 
  ungroup()
```


## Python

:::

### Grouped changes
Sometimes you might need to add a new variable to our table, based on different groups.

::: {.panel-tabset group="language"}
## R
Let's assume we'd have the following summary data:

```{r}
surveys |> 
  group_by(year) |> 
  summarise(n_obs_f = sum(sex == "F", na.rm = TRUE),
            n_obs_m = sum(sex == "M", na.rm = TRUE)) |> 
  ungroup()
```

Now, let's say we'd be interested in the percentage of female observations out of the total of observations where it was scored. We'd have to add a new column. Adding new columns is, as we've seen before, a job for `mutate()`.

```{r}
surveys |> 
  group_by(year) |> 
  summarise(n_obs_f = sum(sex == "F", na.rm = TRUE),
            n_obs_m = sum(sex == "M", na.rm = TRUE)) |> 
  ungroup() |> 
  mutate(female_pct = n_obs_f / (n_obs_f + n_obs_m) * 100)
```

The nice thing about chaining all these commands is that we can quickly build up what we want. We could, for example, easily plot the outcome of this.

```{r}
surveys |> 
  group_by(year) |> 
  summarise(n_obs_f = sum(sex == "F", na.rm = TRUE),
            n_obs_m = sum(sex == "M", na.rm = TRUE)) |> 
  ungroup() |> 
  mutate(female_pct = n_obs_f / (n_obs_f + n_obs_m) * 100) |> 
  ggplot(aes(x = year, y = female_pct)) +
  geom_line()
```


## Python

:::

### To ungroup or not ungroup
Each time you do a grouped operation, it's good practice to remove the grouping afterwards. If you don't, then you might unintentionally be doing operations within the groups later on. Let's illustrate this with an example.

We'll take out any missing values, to simplify things.

::: {.panel-tabset group="language"}
## R

```{r}
obs_count <- surveys |> 
  drop_na() |> 
  group_by(sex, year) |> 
  summarise(n_obs = n())
```

```{r}
obs_count
```

Let's say we now wanted to transform the `n_obs` variable to a percentage of the total number of observations in the entire data set (which is `r surveys |> drop_na() |> nrow()`).

```{r}
obs_count <- obs_count |> 
  mutate(n_obs_pct = n_obs / sum(n_obs) * 100)
```

We'd expect these values in `n_obs_pct` to add up to 100%.

```{r}
sum(obs_count$n_obs_pct)
```

However, they add up to `r sum(obs_count$n_obs_pct)` instead! Why? That's because the table was still grouped by `sex` and as such, the percentages were calculated by each `sex` group. There are two of them (`F`, `M` - we filtered out the missing values), so the percentages add up to 100% *within* each `sex` group.

The way to avoid this issue is to ensure we remove any groups from our table, which we can do with `ungroup()`. Here’s the full string of commands, with the ungrouping step added:


```{r}
obs_count <- surveys |> 
  drop_na() |>                                  # remove all NAs
  group_by(sex, year) |>                        # group by sex, year
  summarise(n_obs = n()) |>                     # get number of rows
  ungroup() |>                                  # ungroup here
  mutate(n_obs_pct = n_obs / sum(n_obs) * 100)  # calculate percentage
```

We can check the percentages again and see that all is well:

```{r}
sum(obs_count$n_obs_pct)
```

## Python
:::

## Summary

::: {.callout-tip}
#### Key points

::: {.panel-tabset group="language"}
## R

- We can split our data into groups and apply operations to each group.
- We can then combine the outcomes in a new table.
- We use `summarise()` to calculate summary statistics (e.g. mean, median, maximum, etc)
- Using pipes with groups (e.g. `group_by() |> summarise()`) we can calculate those summaries across groups.
- We can also filter (`group_by() |>  filter()`) or create new columns (`group_by() |> mutate()`).
- It is good practice to remove grouping (with `ungroup()`) from tables after `group_by()` operations, to avoid issues with retained groupings.

## Python

:::

:::
