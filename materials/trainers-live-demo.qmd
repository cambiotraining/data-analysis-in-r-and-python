---
title: "Live demo exercises"
---

## Section setup

::: {.panel-tabset group="language"}
## R

```{r}
#| message: false
library(tidyverse)
```

## Python

```{python}
# A Python data analysis and manipulation tool
import pandas as pd

# Python equivalent of `ggplot2`
from plotnine import *

# If using seaborn for plotting
import seaborn as sns
import matplotlib.pyplot as plt
```

:::

## DA1: getting started

This is a hands-on demo.

::: {.panel-tabset group="language"}
## R

Live demo RStudio:

* open RStudio
* highlight panels
* change default settings (`.Rdata` and not save workspace)
* set up new RProject  `data-analysis`
* create the subfolders (`data`, `images`, `scripts`)
* create a script
* download and copy the data files into `data`


## Python

Live demo JupyterLab:

* open JupyterLab
* highlight Launcher
* show how to check working directory, change if needed (`data-analysis`)
* create the subfolders (`data`, `images`, `scripts`) 
* create a Notebook
* download and copy the data files into `data`


:::

## DA1: data types

Important to realise that there often is some order to how data types are interpreted. For example, look at the following:

::: {.panel-tabset group="language"}
## R

```{r}
example <- c(22, 87, NA, 32)
```

```{r}
class(example)
```

```{r}
example <- c(22, 87, NA, "unsure")
```

```{r}
class(example)
```


## Python

:::

## DA1: indexing

A bit of a technical detail, but an important one, particularly if you're using both R and Python. The main focus of the example is **not** on the subsetting, it's on the fact that R has 1-based indexing and Python has 0-based indexing.

Furthermore, that R's indexing is inclusive, and Python's exclusive (comparing `1:3` in R vs Python). That said, it's to create awareness of the fact that indexing has to start somewhere and that it can be different between programming languages.

::: {.panel-tabset group="language"}
## R

```{r}
winnings <- c("first", "second", "third", "fourth")
```

The positional index is as follows:

```{r}
seq_along(winnings)
```

So, if we wanted to select the first and third values, we'd do:

```{r}
winnings[c(1, 3)]
```

## Python

```{python}
winnings = ["first", "second", "third", "fourth"]
```

The positional index is as follows:

```{python}
list(range(len(winnings)))
```

So, if we wanted to select the first and third values, we'd do:

```{python}
winnings[0]
winnings[2]
```

:::


## DA2: data exploration

::: {.panel-tabset group="language"}
## R

Read in the data:

```{r}
#| message: false
infections <- read_csv("data/infections.csv")
```

And have a look:

```{r}
#| eval: true
head(infections)
```


## Python

Read in the data:

```{python}
infections = pd.read_csv("data/infections.csv")
```

And have a look:

```{python}
#| eval: true
infections.head()
```

:::

### Data structure

Number of rows & columns:

::: {.panel-tabset group="language"}
## R

```{r}
#| eval: true
nrow(infections)
```

```{r}
#| eval: true
ncol(infections)
```

## Python

```{python}
#| eval: true
infections.shape[0]
```

```{python}
#| eval: true
infections.shape[1]
```


:::

It's good to look at the column attributes: what type of columns are we dealing with and is it what we expect?

::: {.panel-tabset group="language"}
## R

```{r}
#| eval: true
summary(infections)
```

```{r}
#| eval: true
str(infections)
```

## Python

```{python}
#| eval: true
infections.describe()
```

:::

### Quality control checks

It's good to do some basic sanity / quality control checks. For example, if there are different categories in a column, do all the categories we expect show up or are there missing ones / misspelled etc.?

For example, we can check the unique values in a column:

::: {.panel-tabset group="language"}
## R

```{r}
#| eval: true
unique(infections$infection_type)
```

## Python

```{python}
#| eval: true
infections["infection_type"].unique()
```

:::

We can count the number of missing values in the column `infection_type`.

::: {.panel-tabset group="language"}
## R

You read the code "inside-out":

```{r}
#| eval: true
sum(is.na(infections$infection_type))
```

## Python

```{python}
#| eval: true
infections["infection_type"].isna().sum()
```

:::

## DA2: subsetting data

Let's select `patient_id`:

::: {.panel-tabset group="language"}
## R

```{r}
#| eval: false
infections$patient_id
```

## Python

```{python}
#| eval: true
infections.patient_id
```

:::

Or more than 1 column, by column name:

::: {.panel-tabset group="language"}
## R

```{r}
infections[, c("patient_id", "systolic_pressure")]
```

## Python

```{python}
#| eval: true
infections[["patient_id", "systolic_pressure"]]
```

:::

Combine this with selecting only a subset of rows, let's say the first three rows.

::: {.panel-tabset group="language"}
## R

```{r}
#| eval: true
infections[1:3, c("patient_id", "systolic_pressure")]
```

## Python

We need to be aware of the zero-based indexing, also noting that the value after the `:` is *not* included:

```{python}
#| eval: true
infections[["patient_id", "systolic_pressure"]].iloc[0:3]
```

:::

### DA2: simple plots

Let's start with a simple scatterplot, where we plot `body_temperature` on the x-axis and `crp_level` on the y-axis.

::: {.panel-tabset group="language"}
## R

```{r}
ggplot(infections, aes(x = body_temperature, y = crp_level)) +
  geom_point()
```

## Python

```{python}
#| results: hide

p = (ggplot(infections, aes(x = "body_temperature", y = "crp_level")) +
  geom_point())
  
p.show()
```

:::

We can explore this a bit further. For example, we can colour the points based on the `hospital` variable, to see if there are any patterns across the different hospitals:

::: {.panel-tabset group="language"}
## R

```{r}
ggplot(infections, aes(x = body_temperature, y = crp_level,
                       colour = hospital)) +
  geom_point()
```

## Python

```{python}
#| results: hide

p = (ggplot(infections, aes(x = "body_temperature", y = "crp_level",
                            colour = "hospital")) +
  geom_point())
  
p.show()
```

:::

## DA2: facetting data

When we plotted `body_temperature` and `crp_level` against each other and coloured the data based on `hospital`, we ended up with a rather unclear plot. This is probably because there are no clear differences between the hospitals. However, we can separate these data a bit more clearly by using facets.

::: {.panel-tabset group="language"}
## R

```{r}
ggplot(infections, aes(x = body_temperature, y = crp_level,
                       colour = hospital)) +
  geom_point() +
  facet_wrap(facets = vars(hospital))
```

## Python

```{python}
#| results: hide

p = (ggplot(infections, aes(x = "body_temperature", y = "crp_level",
                            colour = "hospital")) +
  geom_point() +
  facet_wrap("~ hospital"))
  
p.show()
```

:::

## DA3: selecting columns

We're practising two things:

1. selecting columns
2. creating columns (and highlight the use by plotting)

Let's see which columns we have:

::: {.panel-tabset group="language"}
## R

```{r}
colnames(infections)
```


## Python

:::

Let's say we only wanted to select some of these.

::: {.panel-tabset group="language"}
## R

```{r}
select(infections, patient_id, body_temperature)
```


## Python

:::

Or select by data type:

::: {.panel-tabset group="language"}
## R

```{r}
select(infections, where(is.numeric))
```

## Python

:::

Or based on a certain phrase within the column heading:

::: {.panel-tabset group="language"}
## R

```{r}
select(infections, contains("_id"))
```


## Python

:::

## DA3: creating columns

There aren't too many variables in our data set that we can transform. However, the CRP levels are a good example. The CRP (C-reactive protein) is a continuous biomarker, often used clinically to indicate inflammation or infection severity. It can be skewed at times, so scaling it could be useful if you're making comparisons across groups.

::: {.callout-note}
## Scaling vs log-transforming

This falls well outside the scope of this course, but it's possible that the question comes up. We could also log-transform our data if there is an issue with skewing etc. Very simply & briefly put:

* use `log()` when the distribution shape is the issue (e.g. skew, tails)
* use `scale()` when the unit or range is the issue (often when comparing across different variables with different units)
* using **both** can also be helpful, where you log-transform first, then scale the data to use in modelling.

:::

We can scale the data where, for each value, we subtract the mean and divide by the standard deviation.

::: {.panel-tabset group="language"}
## R

In R, we can use the `scale()` function to do this.

```{r}
mutate(infections, crp_scaled = scale(crp_level))
```

Let's store this in a temporary object, so we can visualise it.

```{r}
example <- mutate(infections, crp_scaled = scale(crp_level))
```

We can then plot it, adding a reference line at `y = 0`.

```{r}
ggplot(example, aes(x = quarter, y = crp_scaled)) +
  geom_jitter(width = 0.1) +
  geom_hline(yintercept = 0, colour = "blue", linewidth = 1)
```


## Python

:::

## DA3: creating columns (conditional)

Sometimes we need to create new columns based on certain conditions. Let's say we wanted to flag if patients not vaccinated and have been admitted to ICU we consider them as high risk.

We want to encode this in a column `risk_factor`, where we label them as `"high"`. This would then allow us to add other values, such as `"low"` or `"medium"` at a later time.


::: {.panel-tabset group="language"}
## R

```{r}
mutate(infections,
       risk_factor = ifelse(vaccination_status == "unvaccinated" & icu_admission == TRUE, "high", NA))
```


## Python

:::

## DA4: reshaping data

To illustrate reshaping data, we're going to simplify our data set a little bit. First, we'll calculate the **average CRP levels** for each hospital, quarter, infection type, vaccination status and age group.

We'll use that summary table to highlight some use cases for reshaping data from a long to a wide format - and back.

### Creating a summary table for CRP

::: {.panel-tabset group="language"}
## R

```{r}
infections_summary <- infections |> 
  drop_na() |> 
  group_by(hospital, quarter, infection_type, vaccination_status, age_group) |> 
  summarise(mean_crp = round(mean(crp_level, na.rm = TRUE), 2)) |> 
  ungroup()
```

Let's look at the output. We now have `r ncol(infections_summary)` columns, one for each of our grouping variables and at the end the `mean_crp` column containing the average CRP levels (rounded to two digits).

```{r}
head(infections_summary)
```

## Python

:::

### Wide table by quarter

Let's say we'd be interested how the (average) CRP levels change over time across the different groupings. We'd be interested in having the `mean_crp` values for each `quarter` next to each other. That way we'd be able to plot quarterly average CRP levels against each other.

We can do this as follows:

::: {.panel-tabset group="language"}
## R

```{r}
infections_wide <- infections_summary |> 
  pivot_wider(names_from = "quarter",
              values_from = "mean_crp")
```

```{r}
head(infections_wide)
```


## Python

:::

This then allows us to plot the data, for example:

::: {.panel-tabset group="language"}
## R

```{r}
#| message: false
#| warning: false
ggplot(infections_wide, aes(x = Q1, y = Q2)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```


## Python

:::

### Back to long format

We can revert back to a long format with the following:

::: {.panel-tabset group="language"}
## R

```{r}
pivot_longer(infections_wide,
             cols = Q1:Q3,           # columns to pivot
             names_to = "quarter",   # column for headings
             values_to = "mean_crp") # column for values
```


## Python

:::

And all is well with the world again.

## DA4: joining data

In the `infections` data set we have a variable called `hospital`. This contains the following unique entries:

::: {.panel-tabset group="language"}
## R

```{r}
infections |> count(hospital)
```

## Python
:::

Note that for some of the `hospital` entries there are missing data. This is relevant later on, when we're joining.

We're now going to add information on the hospitals, which are stored in `hospital_info.csv`. Let's read in the data:

::: {.panel-tabset group="language"}
## R

```{r}
#| message: false
hospital_info <- read_csv("data/hospital_info.csv")
```


## Python
:::

Look at the data. There are `r hospital_info |> distinct(hospital) |> nrow()` distinct hospital entries, with additional information for each hospital. We have the following variables:

| Variable           | Type        | Description                                                                 |
|--------------------|-------------|-----------------------------------------------------------------------------|
| `hospital`         | character (id) | Unique hospital identifier (`hospital_1` … `hospital_6`).                   |
| `hospital_name`    | character   | Official hospital name (e.g., *Royal London Hospital*).                     |
| `location`         | character   | City where the hospital is located (e.g., London, Manchester).              |
| `bed_capacity`     | integer     | Approximate number of inpatient beds available at the hospital.             |
| `teaching_hospital`| logical     | Indicates if the hospital is a teaching hospital (`TRUE` / `FALSE`).   |



### Left join

First, we'll add the `hospital_info` data to the `infections` data set. We do this with a left-join. We expect hospital info data to be added to our main `infections` table, if the `hospital` value in `infections` matches with the one in `hospital_info`.

::: {.panel-tabset group="language"}
## R

```{r}
infections_left <- left_join(infections, hospital_info, by = "hospital")
```

Let's just select the ID column from `infections`, together with all the columns that have been added.

```{r}
infections_left |> 
  select(patient_id, hospital, hospital_name, location, bed_capacity, teaching_hospital) |> 
  head()
```

We can see that the hospital information is now added to the data. We don't expect any data to have dropped, so the number of observations/rows in `infections_left` should match the original `r nrow(infections)` from `infections`.

```{r}
nrow(infections_left)
```

## Python

:::

### Right join

So, how does a right join then differ from a left join? Well, here we'd be adding the `infections` data to the `hospital_info` data (so, in the other direction). That means that for each `hospital` value that exists in `hospital_info` it will try and find the values that match the `hospital` column in `infections`.

::: {.panel-tabset group="language"}
## R

```{r}
infections_right <- right_join(infections, hospital_info, by = "hospital")
```

Again, the resulting table contains the data from both `infections` and `hospital_info`:

```{r}
head(infections_right)
```

How many observations do we expect? Let's have a look at how many we've got.

```{r}
nrow(infections_right)
```


## Python

:::

Here we see that we have fewer than the original `r nrow(infections)` observations, because we are joining in the other direction. Remember, there are missing values in our `infections` data set (`r sum(is.na(infections$hospital))` in total). When we're joining `infections` **to** `hospital_info`, these entries get dropped, because there is no missing value entry in the `hospital` column of `hospital_info`.

For the eagle-eyed amongst you: we have `r nrow(infections_right)` observations/rows in `infections_right`, whereas there are `r sum(is.na(infections$hospital))` missing values. We might have expected there to be `r nrow(infections) - sum(is.na(infections$hospital))` rows (the difference between the number of rows in `infections` and the number of missing values), but there are `r nrow(infections_right)`.

Why? Well, there is one entry in `hospital_info` that does not appear in `infections`: `hospital_6`. When we right join, this value gets retained, so this adds one additional row to the final output.

::: {.panel-tabset group="language"}
## R

```{r}
infections_right |> count(hospital)
```


## Python

:::

If we wouldn't want that, we'd use inner join.

### Inner join

Inner join will join two tables and only retain values (based on the joining ID) that exist in *both* tables.

::: {.panel-tabset group="language"}
## R

```{r}
infections_inner <- inner_join(infections, hospital_info, by = "hospital")
```

```{r}
nrow(infections_inner)
```

Only the 5 hospitals that appear in the `infections` data set are retained:

```{r}
infections_inner |> count(hospital)
```


## Python

:::

This is entirely expected, since we don't have missing data in `hospital_info` (so all the missing data from `infections` are dropped), nor do we have a `hospital_6` entry in `infections` (so that is dropped too).

### Full join

If we wanted to retain *all* observations, regardless of which table they're from, we'd use a full join.

::: {.panel-tabset group="language"}
## R

```{r}
infections_full <- full_join(infections, hospital_info, by = "hospital")
```

How many rows do we expect? Well, the `r nrow(infections)` from `infections` plus the one extra (`hospital_6` entry) from `hospital_info`:

```{r}
nrow(infections_full)
```

We can check that we've retained all values, by counting the number of observations for each `hospital` value:

```{r}
infections_full |> count(hospital)
```


## Python

:::

We see that **all** `hospital` values are retained, including the missing values *and* the one `hospital_6` value coming from the `hospital_info` data set. Success!
